{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrC-tuIL-ngJ"
   },
   "source": [
    "## Table of contents\n",
    "\n",
    "1. **LLM Configuration**\n",
    "   - Import ChatTogether from langchain_together\n",
    "   - Set up the LLM using ChatTogether with Meta-Llama-3.1-8B-Instruct-Turbo model\n",
    "\n",
    "2. **Basic LLM Interaction**\n",
    "   - Create a simple conversation with system and human messages\n",
    "   - Invoke the LLM and display the response\n",
    "\n",
    "3. **Router Chain Setup**\n",
    "   - Import necessary components from langchain\n",
    "   - Define templates for different types of inquiries:\n",
    "     - Flight status\n",
    "     - Baggage inquiry\n",
    "     - Ticket booking\n",
    "     - General inquiry\n",
    "\n",
    "4. **Destination Chains Configuration**\n",
    "   - Set up destination chains for each inquiry type\n",
    "   - Create a fallback chain for unmatched queries\n",
    "\n",
    "5. **Router Template Definition**\n",
    "   - Define the MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "   - Create the router prompt and chain\n",
    "\n",
    "6. **Multi-Prompt Chain Creation**\n",
    "   - Combine router chain, destination chains, and default chain\n",
    "\n",
    "7. **Testing the Chatbot**\n",
    "   - Run sample queries to test different aspects of the chatbot:\n",
    "     - Flight status inquiry\n",
    "     - General airline safety inquiry\n",
    "     - Ticket upgrade request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jMQslVSxvbb5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LLM Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wrLgFAPJliG",
    "outputId": "c5956307-5c47-4ae2-a8ce-bb2b96324966"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Je m'adore programmer.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 56, 'total_tokens': 64}, 'model_name': 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', 'system_fingerprint': None, 'finish_reason': 'eos', 'logprobs': None}, id='run-6d495c7c-55e1-4013-b358-c073dfc9c158-0', usage_metadata={'input_tokens': 56, 'output_tokens': 8, 'total_tokens': 64})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## setting up the language model\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_together import ChatTogether\n",
    "\n",
    "## load the environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "llm = ChatTogether(api_key=os.getenv(\"TOGETHERAI_API_KEY\"),temperature=0.0, model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Lwoll6iUJ8me",
    "outputId": "efeffcba-d697-472a-f62e-1bbe01e6dd2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je m'adore programmer.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNmyvQLUA_Gb"
   },
   "source": [
    "### Chains in Langchain\n",
    "\n",
    "In LangChain, a \"chain\" refers to a sequence of steps where each step involves processing some input and producing some output, typically using a large language model (LLM) or other tools. \n",
    "\n",
    "Chains allow for creating complex workflows by linking together multiple prompts or actions. This helps in building more sophisticated and structured applications, enhancing modularity, and reusability.\n",
    "\n",
    "They further provide a structured way to manage interactions with LLMs and other tools, making it easier to handle complex logic and stateful interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H7Ib4Y-WKCta"
   },
   "outputs": [],
   "source": [
    "# from langchain.chains.router import MultiPromptChain  # Import for creating a chain with multiple prompts\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser  # Imports for routing logic in LLM chains\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate  # Imports for creating prompt templates\n",
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MTkldoRGKLDZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define templates for handling different types of user queries\n",
    "\n",
    "flight_status_template = \"\"\"You are a helpful airline customer service representative.\n",
    "Answer the following query about flight status. Provide accurate, concise, and friendly information.\n",
    "Here is the query:\n",
    "{input}\"\"\"\n",
    "\n",
    "baggage_inquiry_template = \"\"\"You are a knowledgeable airline customer service representative.\n",
    "Provide information regarding baggage policies, lost baggage, or baggage fees.\n",
    "Here is the query:\n",
    "{input}\"\"\"\n",
    "\n",
    "ticket_booking_template = \"\"\"You are an airline booking agent. Assist the customer in booking, modifying, or canceling a flight.\n",
    "Here is the request:\n",
    "{input}\"\"\"\n",
    "\n",
    "general_inquiry_template = \"\"\"You are a customer service representative at an airline.\n",
    "Answer the following general inquiry about the airline, its services, or policies.\n",
    "Here is the question:\n",
    "{input}\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W4_mPTC7tuhg"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define prompt information for different routes\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"flight_status\",\n",
    "        \"description\": \"Handles inquiries related to flight status.\",\n",
    "        \"prompt_template\": flight_status_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"baggage_inquiry\",\n",
    "        \"description\": \"Good for responding to questions related to baggage, including fees and lost items.\",\n",
    "        \"prompt_template\": baggage_inquiry_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ticket_booking\",\n",
    "        \"description\": \"Handles ticket booking, modification, or cancellation requests.\",\n",
    "        \"prompt_template\": ticket_booking_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"general_inquiry\",\n",
    "        \"description\": \"Good for answering general inquiries about the airline or its services or handling feedbacks.\",\n",
    "        \"prompt_template\": general_inquiry_template\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create destination chain for each query prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Xh1-V8AftugL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/z26yjgq567gdhj2y_0sl53yh0000gn/T/ipykernel_63435/2975751954.py:12: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "# Destination Chains Setup: A loop iterates over each item in prompt_infos,\n",
    "# creates a chain for each feedback type,\n",
    "# and stores it in the destination_chains dictionary.\n",
    "# Each chain is created by combining the ChatPromptTemplate with LLMChain.\n",
    "\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# Create destinations string for router template\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3xVv03Ntucm",
    "outputId": "29f6fe94-6aa1-4e01-fd0b-7928fb84e26b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flight_status': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='You are a helpful airline customer service representative.\\nAnswer the following query about flight status. Provide accurate, concise, and friendly information.\\nHere is the query:\\n{input}'))]), llm=ChatTogether(client=<openai.resources.chat.completions.Completions object at 0x10f492f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f4a6130>, model_name='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', temperature=0.0, openai_api_key=SecretStr('**********'), together_api_key=SecretStr('**********'))),\n",
       " 'baggage_inquiry': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='You are a knowledgeable airline customer service representative.\\nProvide information regarding baggage policies, lost baggage, or baggage fees.\\nHere is the query:\\n{input}'))]), llm=ChatTogether(client=<openai.resources.chat.completions.Completions object at 0x10f492f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f4a6130>, model_name='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', temperature=0.0, openai_api_key=SecretStr('**********'), together_api_key=SecretStr('**********'))),\n",
       " 'ticket_booking': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='You are an airline booking agent. Assist the customer in booking, modifying, or canceling a flight.\\nHere is the request:\\n{input}'))]), llm=ChatTogether(client=<openai.resources.chat.completions.Completions object at 0x10f492f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f4a6130>, model_name='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', temperature=0.0, openai_api_key=SecretStr('**********'), together_api_key=SecretStr('**********'))),\n",
       " 'general_inquiry': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='You are a customer service representative at an airline.\\nAnswer the following general inquiry about the airline, its services, or policies.\\nHere is the question:\\n{input}'))]), llm=ChatTogether(client=<openai.resources.chat.completions.Completions object at 0x10f492f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f4a6130>, model_name='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', temperature=0.0, openai_api_key=SecretStr('**********'), together_api_key=SecretStr('**********')))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uedShQ11BEyz"
   },
   "source": [
    "### Router chains\n",
    "\n",
    "In LangChain, Router Chains are used to dynamically select and route the input to different sub-chains or components based on the input's characteristics or conditions. This is useful when you need to handle different types of inputs or tasks with specialized processing logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g5o1erqotuVF"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a fallback chain for any queries that don't fit a specific category\n",
    "default_prompt = ChatPromptTemplate.from_template(\"reply to this {input} gracefully\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n",
    "\n",
    "# Define router template\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input, select the prompt best suited for the input.\n",
    "You will be given the names of the available prompts and a description of what the prompt is best suited for.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ original input\n",
    "}}}}\n",
    "<< CANDIDATE PROMPTS >> {destinations}\n",
    "\n",
    "<< INPUT >> {{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWJ3Fdb_PpTi"
   },
   "source": [
    "Router Template: This template instructs the model on how to choose the appropriate feedback chain based on the input. It describes the available prompt options and asks the model to select the most suitable one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R9CS3KiXvwYp"
   },
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "\n",
    "router_prompt = PromptTemplate( template=router_template, input_variables=[\"input\"], output_parser=RouterOutputParser(), )\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t9Bjj93P1Jc"
   },
   "source": [
    "## Combining the chains with `MultiPromptChain`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZDeqBD2lwCSl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/z26yjgq567gdhj2y_0sl53yh0000gn/T/ipykernel_63435/2647798521.py:3: LangChainDeprecationWarning: Use RunnableLambda to select from multiple prompt templates. See example in API reference: https://api.python.langchain.com/en/latest/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html\n",
      "  chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain, verbose=True )\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain, verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing it with different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "EeaAhfcMwEYl",
    "outputId": "fe7cf70b-e380-466b-98c9-57d2f5434784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "flight_status: {'input': 'What is the current status of flight AA123?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the current status of flight AA123?',\n",
       " 'text': \"I'd be happy to help you with the status of flight AA123. \\n\\nTo check the current status, I'll need to look up the flight information. Can you please tell me the departure and arrival cities for flight AA123, as well as the date of travel? This will help me provide you with the most accurate and up-to-date information.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke( \"What is the current status of flight AA123?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "1McGibECwKnG",
    "outputId": "5ce28e17-acfd-43f6-de2e-9ec0749ba08c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "general_inquiry: {'input': \"Can you tell me about your airline's safety protocols?\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Can you tell me about your airline's safety protocols?\",\n",
       " 'text': \"Thank you for choosing to fly with us. I'd be happy to provide you with information about our airline's safety protocols.\\n\\nAt [Airline Name], the safety of our passengers and crew is our top priority. We take every precaution to ensure that our flights are operated safely and efficiently. Here are some of the key safety protocols we have in place:\\n\\n1. **Regular Maintenance**: Our aircraft undergo regular maintenance checks to ensure that they are airworthy and meet the highest safety standards. Our maintenance team conducts thorough inspections and repairs to prevent any potential issues.\\n\\n2. **Pilot Training**: Our pilots undergo rigorous training and must meet the highest standards set by regulatory bodies. They are trained to handle emergency situations and are equipped with the latest technology to ensure safe flight operations.\\n\\n3. **Safety Briefings**: Before every flight, our crew provides a comprehensive safety briefing to all passengers, covering emergency procedures, exit locations, and the use of safety equipment.\\n\\n4. **Emergency Equipment**: Our aircraft are equipped with state-of-the-art emergency equipment, including oxygen masks, fire extinguishers, and emergency exits.\\n\\n5. **Crew Training**: Our cabin crew undergo extensive training in emergency procedures, including evacuation drills, first aid, and crisis management.\\n\\n6. **Safety Audits**: We conduct regular safety audits to ensure that our procedures and protocols are up to date and meet the highest standards.\\n\\n7. **Collaboration with Regulatory Bodies**: We work closely with regulatory bodies, such as the Federal Aviation Administration (FAA) and the European Aviation Safety Agency (EASA), to ensure that we comply with all safety regulations.\\n\\n8. **Passenger Briefings**: We provide clear and concise information to passengers about our safety procedures, including the use of seatbelts, electronic devices, and emergency exits.\\n\\n9. **Emergency Response Plan**: We have a comprehensive emergency response plan in place, which includes procedures for handling medical emergencies, security threats, and other potential hazards.\\n\\n10. **Continuous Improvement**: We continuously review and improve our safety protocols to ensure that we stay ahead of the curve in terms of safety standards.\\n\\nAt [Airline Name], we take pride in our commitment to safety and strive to provide a safe and enjoyable flying experience for all our passengers. If you have any specific questions or concerns, please don't hesitate to ask.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Can you tell me about your airline's safety protocols?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "RJ6GXt2-xXHV",
    "outputId": "58a69dda-850a-4cef-c9a8-12b1a1c76de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "ticket_booking: {'input': 'how can i upgrade my flight ticket that is already booked.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can i upgrade my flight ticket that is already booked.',\n",
       " 'text': \"To upgrade your existing flight ticket, I'll need to check a few things first. Can you please provide me with the following information:\\n\\n1. Your booking reference number or ticket number?\\n2. Your name as it appears on the ticket?\\n3. The flight number and date of travel?\\n4. The class of service you're currently booked in (economy, premium economy, business, or first class)?\\n5. The class of service you'd like to upgrade to?\\n\\nAdditionally, I'll need to let you know that upgrades are subject to availability and may incur an additional fee. If there are any available upgrades, I can provide you with the details and prices.\\n\\nAlso, please note that some airlines have specific upgrade policies, such as:\\n\\n- Upgrades may be available at check-in or at the gate, depending on the airline's policy.\\n- Some upgrades may require a higher fare or a fee to be paid.\\n- Upgrades may not be available on all flights or routes.\\n\\nOnce I have this information, I can assist you in checking for available upgrades and provide you with the next steps.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"how can i upgrade my flight ticket that is already booked.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
